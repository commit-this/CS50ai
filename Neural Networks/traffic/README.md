For this model I started with the structure given in the lecture source notes, from 'handwriting'. Then I tweaked parameters like adding hidden layers, adjusting the number of layer nodes and the number of filters in the convolutional layer, changing the pool size adding and adjusting dropout. The compilation parameters were kept the same as in the lecture code.

Ultimately I settled on a convolutional layer with 64 filters, with a max pooling layer using 3x3 pool size to reduce the size of the image. Adding more convolutional layers seemed to reduce accuracy. Then a hidden layer with 256 nodes and a dropout of 0.3. Increasing the number of nodes beyond that had minimal effect on accuracy while significantly increasing runtime, as did adding additional hidden layers Similarly, I kept the dropout at a moderate level to help prevent overfitting while not dropping so many layers that it would affect how well the model learned. One thing I kept an eye out for was whether the model worked better on the training set than the testing set, as that would indicate overfitting. The model I ended up on has 90%-93% accuracy on training and ~93%-94% accuracy on testing (within the CS50 codespace).